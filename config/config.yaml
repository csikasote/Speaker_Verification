training: !!bool "false"
device: 0 #gpu id
seed: 777
---
data:
    p1: './data/id_02542_00057.wav'
    p2: './data/id_02181_00021.wav'
    train_path: './dataVoxCeleb1/Audio/dev/processed'
    train_path_unprocessed: './dataVoxCeleb1/Audio/dev/wav' #*/wav/speaker_id/session_id/file.wav
    test_meta_path: './dataJusanBank/jusan_test_full_gender.txt'
    test_path: './dataJusanBank/wav'
    test_path_unprocessed: './dataVoxCeleb1/Audio/test/wav'
    feat_type: 'spec' #feature type: 'spec' (spectogram), 'logmel' (logmel spectogram)
    sr: 16000
    nfft: 512 #For mel spectrogram preprocess
    window: 0.025 #(s)
    hop: 0.01 #(s)
    nmels: 40 #Number of mel energies
    tisv_frame: 250 #Max number of time steps/frames in input after preprocess
---
model:
    type: 'TResNet34' #model type: 'TResNet32' (Thin ResNet34), 'RNN'
    hidden: 768 #Number of LSTM hidden layer units
    num_layer: 3 #Number of LSTM layers
    proj: 512 #Embedding size
    ghost_centers: 0
    vlad_centers: 10
    dropout: 0.0
    #Model path for testing, inference, or resuming training
    model_path: 'pretrained.pth'
---
train:
    N: 256 #Number of speakers in batch
    M: 1 #Number of utterances per speaker
    num_workers: 0 #number of workers for dataloader
    lr: 0.001
    optim: 'Adam' #optimizer type: 'Adam' (lr 0.001), 'SGD', 'Adadelta' (lr 0.1)
    loss: 'si' #loss type: "si" (Speaker identification), 'ge2e' (generaliazed E2E loss), 'hybrid'
    warmup_epochs: 1 #number of warmup epochs with lr set to lr/10
    wd: 0.0001 #weight decay
    epochs: 250 #Max training epoch
    patience: 10
    threshold: 0.0001
    factor: 0.5
    log_interval: 100 #Iterations before printing progress
    test_interval: 10 #test on sp. verification after test_interval epochs
    checkpoint_dir: './models'
    restore: !!bool "true" #Resume training from previous model path
